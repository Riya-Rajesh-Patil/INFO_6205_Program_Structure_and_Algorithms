{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Name : Riya Patil\n",
    "## Professor : Nik Bear Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. (10 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "In the context of Hopfield Neural Networks, define and discuss the characteristics that determine whether a given state of the network can be considered an \"attractor.\" Describe how these attractors contribute to the network's ability to recall patterns.\n",
    "\n",
    "**Input Format:** A description of a state in a Hopfield Neural Network. This description should include the values of neurons in the network.  \n",
    "\n",
    "**Output Format:** A detailed explanation assessing whether the given state is an attractor, based on the principles governing Hopfield Networks.  \n",
    "\n",
    "**Sample Inputs and Outputs**  \n",
    "- **Sample Input:** A state of a Hopfield Network with 4 neurons: `[1, -1, 1, -1]`.\n",
    "- **Sample Output:** \"This state is an attractor because it satisfies the energy minimization principle of Hopfield Networks, leading to stable, minimal energy configuration.\"\n",
    "\n",
    "- **Sample Input:** A state of a Hopfield Network with 3 neurons: `[0, 1, -1]`.\n",
    "- **Sample Output:** \"This state is not an attractor as it does not correspond to a stable, low-energy configuration in the network.\"\n",
    "\n",
    "**Constraints**  \n",
    "- The number of neurons (`N`) in the network should be a positive integer, typically `N > 2` to allow for meaningful pattern dynamics.\n",
    "- Neuron values should be binary or bipolar (i.e., 1 and -1 for bipolar representation).\n",
    "\n",
    "**Solution:**  \n",
    "To solve the proposed problem about attractors in Hopfield Neural Networks, we need to understand the concept of attractors and how to determine whether a given state in a Hopfield network is an attractor. An attractor in the context of Hopfield networks is a stable state that the network will converge to from a set of initial states. These attractors represent stored patterns or memories in the network.  \n",
    "\n",
    "A state in a Hopfield Network is considered an attractor if it is a point of local minimum in the network's energy landscape. The energy of a state in a Hopfield Network is given by the equation:  \n",
    "\n",
    "E = -(1/2)âˆ‘(i=!j).w_i_j.s_i.s_j\n",
    "\n",
    "where s_i and s_j are the states of neurons \\( i \\) and \\( j \\), and \\( w_{ij} \\) is the weight of the connection between these neurons.  \n",
    "\n",
    "A state is an attractor if a small perturbation (like flipping the state of a single neuron) does not lead to a significant change in the overall state of the network. In other words, the network will eventually settle back into this state or a very similar one.  \n",
    "\n",
    "**Pseudocode**\n",
    "To check if a given state is an attractor:\n",
    "\n",
    "function isAttractor(network_state, weights_matrix):\n",
    "    for each neuron i in network_state:\n",
    "        test_state = flip the state of neuron i in network_state\n",
    "        if energy(test_state, weights_matrix) < energy(network_state, weights_matrix):\n",
    "            return False\n",
    "    return True  \n",
    "\n",
    "**Proof of Correctness**  \n",
    "The correctness of this solution is based on the fundamental principles of Hopfield Networks. An attractor, being a stable state, should have lower energy than its neighboring states. By iterating over each neuron and flipping its state, we simulate a small perturbation. If the energy of the network with any flipped neuron is lower than the original state, the original state is not at a minimum energy point, and thus not an attractor.  \n",
    "\n",
    "This approach is grounded in the energy minimization principle of Hopfield Networks, which states that the network evolves towards states of minimum energy. The Python code effectively calculates and compares these energy states, providing a practical way to determine if a given state is an attractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 state is an attractor: False\n",
      "Sample 2 state is an attractor: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_energy(state, weights):\n",
    "    return -0.5 * np.sum(np.outer(state, state) * weights)\n",
    "\n",
    "def is_attractor(state, weights):\n",
    "    for i in range(len(state)):\n",
    "        test_state = np.copy(state)\n",
    "        test_state[i] *= -1  # Flip the state of the i-th neuron\n",
    "        if calculate_energy(test_state, weights) < calculate_energy(state, weights):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Example usage for Sample Inputs and Outputs\n",
    "# Sample 1: A state with 4 neurons: [1, -1, 1, -1]\n",
    "weights_sample1 = np.random.rand(4, 4)  # Random weights for illustrative purposes\n",
    "weights_sample1 = (weights_sample1 + weights_sample1.T) / 2  # Make the matrix symmetric\n",
    "state_sample1 = np.array([1, -1, 1, -1])\n",
    "result_sample1 = is_attractor(state_sample1, weights_sample1)\n",
    "\n",
    "# Sample 2: A state with 3 neurons: [0, 1, -1]\n",
    "weights_sample2 = np.random.rand(3, 3)  # Random weights for illustrative purposes\n",
    "weights_sample2 = (weights_sample2 + weights_sample2.T) / 2  # Make the matrix symmetric\n",
    "state_sample2 = np.array([0, 1, -1])  # Note: 0 is not a valid state in Hopfield networks, typically it's either 1 or -1\n",
    "result_sample2 = is_attractor(state_sample2, weights_sample2)\n",
    "\n",
    "# Displaying results\n",
    "print(f\"Sample 1 state is an attractor: {result_sample1}\")\n",
    "print(f\"Sample 2 state is an attractor: {result_sample2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sample 1: The code checks if the state [1, -1, 1, -1] is an attractor given a set of weights. Since the actual weights matrix determines the dynamics of the network, a random symmetric matrix is used for demonstration. The output will indicate whether this state is an attractor under these conditions.  \n",
    "- Sample 2: Similar to Sample 1, but with a state of [0, 1, -1]. Note that Hopfield networks typically use binary or bipolar states (1 or -1), so a state with 0 may not be valid in traditional Hopfield networks. The code still checks for attractor status for demonstration purposes.  \n",
    "\n",
    "**Reflection:** Reflecting on my task with ChatGPT about Hopfield Neural Networks, I realized the importance of precise problem formulation in algorithms. ChatGPT's suggestion to focus on attractors was a clever pivot from the original stability question, maintaining the essence while introducing a new angle. This process highlighted the critical role of a well-defined problem statement in complex topics like neural networks.  \n",
    "\n",
    "During the solution phase, ChatGPT's ability to offer both theoretical explanations and practical Python code was impressive. However, tailoring the code to match specific sample inputs and outputs was challenging. This task underlined the importance of aligning theory with practical application, a key skill in algorithm design.  \n",
    "\n",
    "This exercise deepened my understanding of algorithmic problem design, particularly in how theoretical concepts are translated into executable solutions. ChatGPT served as a valuable bridge between these two aspects, enhancing my learning in algorithmic studies and highlighting the intersection of theory and practice in the field.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. (5 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    "In a virtual gardening game, players plant seeds to grow various types of flowers. There are `k` different types of flowers. Each time a player plants a seed, it randomly grows into one of the `k` types of flowers with equal probability. The objective is to determine how many seeds a player needs to plant on average before they can expect to have at least one of each type of flower in their garden.\n",
    "\n",
    "**Input Format:** A single integer `k`, representing the number of different types of flowers.  \n",
    "\n",
    "**Output Format:** A single integer, representing the average number of seeds that need to be planted to expect at least one of each type of flower.  \n",
    "\n",
    "**Sample Inputs and Outputs**  \n",
    "- **Sample Input 1:** `3`\n",
    "- **Sample Output 1:** `5.5`\n",
    "- **Explanation:** On average, a player needs to plant approximately 5.5 seeds to have at least one of each of the 3 types of flowers.\n",
    "\n",
    "- **Sample Input 2:** `5`\n",
    "- **Sample Output 2:** `11.41`\n",
    "- **Explanation:** On average, a player needs to plant approximately 11.41 seeds to have at least one of each of the 5 types of flowers.\n",
    "\n",
    "**Constraints**  \n",
    "`1 <= k <= 50`. This constraint ensures the problem remains computationally manageable and realistic within the context of a game.\n",
    "\n",
    "**Solution:** \n",
    "To solve this problem, we can apply the principles of the \"Coupon Collector's Problem,\" a well-known concept in probability theory. The problem essentially asks for the expected number of trials (in this case, planting seeds) to collect all `k` different types of items (flowers).\n",
    "\n",
    "**Pseudocode**\n",
    "Here's a pseudocode for calculating the expected number of seeds to plant:\n",
    "\n",
    "function expectedNumberOfSeeds(k):\n",
    "    expected_seeds = 0\n",
    "\n",
    "    for i from 1 to k:\n",
    "        probability_of_new_flower = 1 - (i - 1) / k\n",
    "        expected_seeds += 1 / probability_of_new_flower\n",
    "\n",
    "    return expected_seeds\n",
    "\n",
    "**Explanation**\n",
    "1. **Initialization:** We initialize `expected_seeds` to 0. This variable will accumulate the expected number of seeds needed to get each new type of flower.\n",
    "2. **Iteration:** We loop through each type of flower from 1 to `k`.\n",
    "3. **Probability Calculation:** For each iteration, we calculate the probability of planting a new type of flower that we don't already have. This is done by `1 - (i - 1) / k`, where `(i - 1) / k` is the probability of planting a type we already have, and `1 - (i - 1) / k` is the probability of getting a new type.\n",
    "4. **Accumulating Expected Seeds:** We add the inverse of this probability to our `expected_seeds`. The inverse (`1 / probability_of_new_flower`) represents the expected number of trials (seed plantings) to get one successful outcome (a new type of flower).\n",
    "\n",
    "**Proof of Correctness**  \n",
    "\n",
    "The correctness of this solution is based on the principles of expected value in probability theory. The expected number of trials to get a success in a Bernoulli process (a process with only two outcomes, like flipping a coin) is `1/p`, where `p` is the probability of success. In our case, the probability of success changes with each new type of flower we get because the probability of getting a new type decreases as we collect more types.  \n",
    "\n",
    "For the first flower, the probability of success is `1` (since any flower will be a new type). For the second type of flower, the probability of success is `1 - 1/k` (since there's only one type we already have, and `k - 1` types we don't have). This pattern continues, decreasing the probability of getting a new type with each additional type collected.  \n",
    "\n",
    "Adding these probabilities gives us the expected total number of seeds to plant to collect all `k` types. This approach is a standard method to solve the Coupon Collector's Problem and is well-supported in probability theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 3 types of flowers, the expected number of seeds to plant is approximately 5.50\n",
      "For 5 types of flowers, the expected number of seeds to plant is approximately 11.42\n"
     ]
    }
   ],
   "source": [
    "def expected_number_of_seeds(k):\n",
    "    expected_seeds = 0\n",
    "\n",
    "    for i in range(1, k + 1):\n",
    "        probability_of_new_flower = 1 - (i - 1) / k\n",
    "        expected_seeds += 1 / probability_of_new_flower\n",
    "\n",
    "    return expected_seeds\n",
    "\n",
    "# Sample Input and Output\n",
    "samples = [3, 5]\n",
    "\n",
    "for k in samples:\n",
    "    expected_seeds = expected_number_of_seeds(k)\n",
    "    print(f\"For {k} types of flowers, the expected number of seeds to plant is approximately {expected_seeds:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection:** Reflecting on the task of creating a problem analogous to the \"Coupon Collector's Problem,\" I appreciate how ChatGPT's creative suggestion of a virtual gardening game provided a fresh yet relevant scenario. This task emphasized the importance of maintaining the core concept - probability and collection - while introducing a novel context. Crafting a clear problem statement, complete with inputs, outputs, and constraints, was pivotal. ChatGPT's efficiency in structuring these components was invaluable, ensuring the problem was both understandable and educationally sound.  \n",
    "\n",
    "The solution phase, involving pseudocode and Python coding, highlighted ChatGPT's versatility. Despite a technical glitch in executing the Python code, the logic of the provided solution was sound and well-aligned with algorithmic principles. This demonstrated the tool's capability in bridging theoretical problem-solving with practical application, an essential skill in algorithm design.  \n",
    "\n",
    "This exercise provided significant insights into problem design within the realm of algorithms. The balance between originality and adherence to the original problem's spirit was a nuanced challenge. ChatGPT's role was instrumental in navigating this balance, underscoring the potential of AI tools in enhancing learning and understanding in complex subjects like algorithms. The experience reinforced the value of clear problem structuring and the practical application of theoretical concepts, crucial aspects in the field of algorithmic studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. (10 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "\"SlideBox\" is a 2-D grid-based puzzle game with the following rules:  \n",
    "1. The game consists of a square grid filled with some unit-square boxes, each occupying a cell of the grid. A player is also positioned within a cell on this grid.\n",
    "2. The player can move to any adjacent cell that is not occupied by a box.\n",
    "3. The player can slide any adjacent box, and the box moves in that direction to the nearest available space, stopping before a wall or another box.\n",
    "4. Sliding means moving the box horizontally or vertically, but not diagonally.\n",
    "5. The objective is to move the boxes to designated target positions on the grid.\n",
    "6. The game is solved when all boxes are on their target positions.  \n",
    "\n",
    "A solution to SlideBox is specified as a sequence of moves:  \n",
    "- `MovePlayer(x, y)`: moves the player from their current position to the position (x, y).\n",
    "- `SlideBox(x, y)`: slides a box from its current position to the position (x, y).  \n",
    "\n",
    "**Input Format:**  \n",
    "A grid representing the initial state of the game, including the positions of the boxes, the player, and the target positions for the boxes.    \n",
    "\n",
    "**Output Format:**  \n",
    "A sequence of moves (`MovePlayer` and `SlideBox`) that leads to all boxes being on their target positions.  \n",
    "\n",
    "**Sample Input:**  \n",
    "  Grid Size: 4x4  \n",
    "  Player Position: (0, 0)  \n",
    "  Box Positions: [(1, 1), (2, 2)]  \n",
    "  Target Positions: [(3, 3), (3, 0)]  \n",
    "\n",
    "**Sample Output:**  \n",
    "  MovePlayer(1, 1)  \n",
    "  SlideBox(3, 3)  \n",
    "  MovePlayer(2, 2)  \n",
    "  SlideBox(3, 0)  \n",
    "\n",
    "**Constraints**  \n",
    "- The grid size is limited to a maximum of 10x10 cells.\n",
    "- The number of boxes does not exceed the number of target positions.\n",
    "- Boxes and the player cannot move diagonally.\n",
    "- The initial configuration ensures that the game is solvable.  \n",
    "\n",
    "**Solution:**  \n",
    "To solve the \"SlideBox\" problem, we need an algorithm that can efficiently determine the sequence of moves leading to the solution. This problem is similar to many classic pathfinding and puzzle-solving problems in computer science. The key challenge is to navigate the player to the correct positions to slide boxes to their target locations, while ensuring the player and boxes do not block each other's paths.  \n",
    "- State Representation: Represent the game state as a grid with player and box positions. Each state change occurs either by moving the player or sliding a box.\n",
    "- Search Algorithm: Use a search algorithm like A* or BFS (Breadth-First Search) to explore possible moves. The algorithm should consider both moving the player and sliding boxes.  \n",
    "- Heuristics for Pathfinding: If using A*, a heuristic function is needed. A simple heuristic could be the sum of the Manhattan distances from each box to its target position.  \n",
    "- Goal Check: The goal is reached when all boxes are on their target positions. The algorithm stops and returns the sequence of moves.  \n",
    "\n",
    "**Pseudocode**\n",
    "function SlideBoxSolver(grid, player_position, box_positions, target_positions):\n",
    "    Initialize an empty queue for states to explore\n",
    "    Add the initial state (grid, player_position, box_positions) to the queue\n",
    "\n",
    "    while queue is not empty:\n",
    "        current_state = queue.dequeue()\n",
    "        if current_state meets the goal condition:\n",
    "            return the sequence of moves to reach current_state\n",
    "\n",
    "        for each possible move from current_state:\n",
    "            new_state = apply_move(current_state, move)\n",
    "            if new_state is valid and not visited:\n",
    "                add new_state to queue\n",
    "\n",
    "    return \"No solution\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No solution\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "\n",
    "def is_goal_state(state, target_positions):\n",
    "    return set(state['box_positions']) == set(target_positions)\n",
    "\n",
    "def get_adjacent_positions(position):\n",
    "    x, y = position\n",
    "    return [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]\n",
    "\n",
    "def is_valid_position(position, grid):\n",
    "    x, y = position\n",
    "    if 0 <= x < len(grid) and 0 <= y < len(grid[0]):\n",
    "        return grid[x][y] == 'empty'\n",
    "    return False\n",
    "\n",
    "def get_possible_moves(state):\n",
    "    moves = []\n",
    "    player_pos = state['player_position']\n",
    "    box_positions = state['box_positions']\n",
    "    \n",
    "    for new_pos in get_adjacent_positions(player_pos):\n",
    "        if is_valid_position(new_pos, state['grid']):\n",
    "            if new_pos in box_positions:\n",
    "                opposite_pos = (new_pos[0] + (new_pos[0] - player_pos[0]), new_pos[1] + (new_pos[1] - player_pos[1]))\n",
    "                if is_valid_position(opposite_pos, state['grid']) and opposite_pos not in box_positions:\n",
    "                    moves.append(('SlideBox', new_pos, opposite_pos))\n",
    "            else:\n",
    "                moves.append(('MovePlayer', new_pos))\n",
    "    \n",
    "    return moves\n",
    "\n",
    "def apply_move(state, move):\n",
    "    new_state = state.copy()\n",
    "    new_state['grid'] = [row[:] for row in state['grid']]\n",
    "    new_state['box_positions'] = state['box_positions'].copy()\n",
    "    move_type, *positions = move\n",
    "\n",
    "    if move_type == 'MovePlayer':\n",
    "        new_state['player_position'] = positions[0]\n",
    "        new_state['grid'][positions[0][0]][positions[0][1]] = 'player'\n",
    "        new_state['grid'][state['player_position'][0]][state['player_position'][1]] = 'empty'\n",
    "    elif move_type == 'SlideBox':\n",
    "        box_pos, new_box_pos = positions\n",
    "        new_state['box_positions'].remove(box_pos)\n",
    "        new_state['box_positions'].append(new_box_pos)\n",
    "        new_state['grid'][new_box_pos[0]][new_box_pos[1]] = 'box'\n",
    "        new_state['grid'][box_pos[0]][box_pos[1]] = 'empty'\n",
    "\n",
    "    return new_state\n",
    "\n",
    "def slide_box_solver(grid, player_position, box_positions, target_positions):\n",
    "    queue = Queue()\n",
    "    initial_state = {'grid': grid, 'player_position': player_position, 'box_positions': box_positions, 'moves': []}\n",
    "    queue.put(initial_state)\n",
    "\n",
    "    visited = set()\n",
    "    while not queue.empty():\n",
    "        current_state = queue.get()\n",
    "        if is_goal_state(current_state, target_positions):\n",
    "            return current_state['moves']\n",
    "\n",
    "        for move in get_possible_moves(current_state):\n",
    "            new_state = apply_move(current_state, move)\n",
    "            state_key = (tuple(new_state['player_position']), tuple(sorted(new_state['box_positions'])))\n",
    "            if state_key not in visited:\n",
    "                visited.add(state_key)\n",
    "                new_state['moves'] = current_state['moves'] + [move]\n",
    "                queue.put(new_state)\n",
    "\n",
    "    return \"No solution\"\n",
    "\n",
    "# Define the grid\n",
    "grid = [['empty' for _ in range(4)] for _ in range(4)]\n",
    "\n",
    "# Define player and box positions\n",
    "player_position = (0, 0)\n",
    "box_positions = [(1, 1), (2, 2)]\n",
    "target_positions = [(3, 3), (3, 0)]\n",
    "\n",
    "# Set initial player and box positions on the grid\n",
    "grid[player_position[0]][player_position[1]] = 'player'\n",
    "for bx, by in box_positions:\n",
    "    grid[bx][by] = 'box'\n",
    "\n",
    "# Find the solution\n",
    "solution = slide_box_solver(grid, player_position, box_positions, target_positions)\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correctness of this solution hinges on the comprehensive exploration of the game state space. Breadth-First Search (BFS) is used here due to its completeness; it guarantees finding a solution if one exists. The challenge lies in efficiently exploring the state space and avoiding revisiting states. The algorithm checks each state to see if the goal is achieved and explores all possible moves from each state, ensuring that no possible solution is missed.  \n",
    "\n",
    "The primary limitation of this approach is its potential computational complexity, as the number of possible states can be large. Optimization techniques like pruning visited states or more intelligent heuristics in an A* implementation could be necessary for larger or more complex instances of the problem.  \n",
    "\n",
    "**Reflection:** Reflecting on the SlideBox puzzle task, ChatGPT's role in shaping the problem was crucial. It helped maintain the essence of a grid-based puzzle while introducing unique elements, highlighting the importance of precise problem definition in algorithmic design.  \n",
    "\n",
    "The transition from problem formulation to creating a working Python solution was challenging. Despite ChatGPT providing a foundational code structure, integrating complex game logic and handling various states required significant effort. This phase underscored the intricacies of algorithm development and the necessity for thorough testing and refinement.  \n",
    "\n",
    "Overall, this experience enhanced my understanding of algorithm design, particularly in game-based problems. While ChatGPT was a valuable aid, it emphasized that AI tools are supplements to human creativity and problem-solving in algorithms, not replacements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. (5 marks)  \n",
    "\n",
    "**Problem Statement** \n",
    "In the context of Hopfield Neural Networks, explore the criteria that define a state as an \"energy minimum.\" Discuss the implications of these criteria on the network's ability to store and retrieve patterns. Explain how the concept of energy minimum relates to the stability and efficiency of pattern recall in these networks.  \n",
    "\n",
    "**Input Format:**  \n",
    "A detailed description of a state in a Hopfield Neural Network, which includes the states (values) of all neurons in the network and the weight matrix defining the connections between them.  \n",
    "\n",
    "**Output Format:**  \n",
    "An analytical explanation determining if the given state is an energy minimum, followed by an assessment of the network's capability to store and retrieve the corresponding pattern.  \n",
    "\n",
    "**Sample Input:**  \n",
    "  - Neuron States: `[1, -1, 1, -1]`\n",
    "  - Weight Matrix: `[[0, 1, -1, 1], [1, 0, 1, -1], [-1, 1, 0, 1], [1, -1, 1, 0]]`  \n",
    "\n",
    "**Sample Output:**  \n",
    "\"The given state is an energy minimum due to its stability under the network's dynamics. This state effectively represents a stored pattern that the network can reliably recall.\"\n",
    "\n",
    "**Sample Input:**  \n",
    "  - Neuron States: `[1, 1, -1, -1]`\n",
    "  - Weight Matrix: `[[0, -1, 1, -1], [-1, 0, -1, 1], [1, -1, 0, -1], [-1, 1, -1, 0]]`  \n",
    "\n",
    "**Sample Output:**  \n",
    "\"The given state is not an energy minimum, as small perturbations can lead to a different state. This instability affects the network's pattern storage and retrieval capabilities.\"  \n",
    "\n",
    "**Constraints**  \n",
    "- The neurons' states should be binary or bipolar (i.e., 1 and -1).\n",
    "- The weight matrix should be symmetric, i.e., \\( w_{ij} = w_{ji} \\), to reflect the undirected nature of the network.\n",
    "- The diagonal elements of the weight matrix (self-connections) should be zero.  \n",
    "\n",
    "**Solution:**  \n",
    "To address the question about the criteria for a state to be an \"energy minimum\" in a Hopfield Neural Network and its relation to the network's ability to store and retrieve patterns, we need to delve into the theoretical aspects of Hopfield Networks and the concept of energy in such systems.\n",
    "\n",
    "1. **Energy in Hopfield Networks:** The energy of a state in a Hopfield Network is given by the formula:\n",
    "   \\[ E = -\\frac{1}{2} \\sum_{i \\neq j} w_{ij} s_i s_j \\]\n",
    "   Here, \\( s_i \\) and \\( s_j \\) are the states of neurons \\( i \\) and \\( j \\), respectively, and \\( w_{ij} \\) is the weight of the connection between these neurons.\n",
    "\n",
    "2. **Energy Minimum Criteria:**\n",
    "   - A state is at an energy minimum if any small change to the state would increase the network's energy.\n",
    "   - Mathematically, for a state to be an energy minimum, flipping the state of any single neuron should not decrease the total energy.\n",
    "\n",
    "3. **Relation to Pattern Storage and Retrieval:**\n",
    "   - Hopfield Networks store patterns as energy minima. These are stable states which the network can converge to from various initial states.\n",
    "   - When the network is given a state that is close to one of these stored patterns (minima), it will evolve to the pattern, effectively retrieving it.\n",
    "\n",
    "**Sample Calculation**  \n",
    "Consider a Hopfield Network with a state `[1, -1, 1, -1]` and a weight matrix:  \n",
    "\n",
    "[[0, 1, -1, 1],  \n",
    " [1, 0, 1, -1],  \n",
    " [-1, 1, 0, 1],  \n",
    " [1, -1, 1, 0]]  \n",
    "  \n",
    "- Calculate the energy of this state.  \n",
    "- Flip each neuron's state and calculate the new energy to see if the original state is an energy minimum.  \n",
    "If flipping any neuron results in a higher energy state, the original state is at an energy minimum and represents a stable pattern that the network can store and recall.  \n",
    "\n",
    "**Proof of Correctness**  \n",
    "The correctness of this approach is based on the fundamental dynamics of Hopfield Networks. By definition, these networks tend to evolve towards states of lower energy. Therefore, an energy minimum state is inherently stable since any small change increases energy, causing the network to revert to the original state. This stability is what allows Hopfield Networks to recall patterns: given an input close to a stored pattern (an energy minimum), the network will evolve to the pattern, thereby retrieving it.  \n",
    "This solution offers a theoretical understanding of how energy minima in Hopfield Networks relate to their pattern storage and retrieval capabilities. For a practical implementation, one would need to simulate a Hopfield Network and observe its dynamics with different inputs and weight configurations.  \n",
    " \n",
    "**Reflection:** Reflecting on my experience with the Hopfield Neural Network task, I found ChatGPT's assistance crucial in reshaping the original question. Its ability to understand and adapt the underlying concepts of Hopfield Networks into a new, yet related question demonstrated the importance of deep subject knowledge in problem design. This step highlighted the complexity involved in crafting conceptually similar yet distinct questions.  \n",
    "The next challenge was to provide a clear solution, where ChatGPT's theoretical input was pivotal. However, translating these theories into a comprehensible explanation required a delicate balance of technical accuracy and clarity. This phase underscored the tool's role as a guide, emphasizing the need for my own deep understanding to articulate the solution fully.  \n",
    "Overall, this task enlightened me on problem design in algorithms, teaching me the essence of a problem lies in its core concepts. ChatGPT proved to be an insightful facilitator, but it also reinforced that such tools are supplements to, not replacements for, human intellect and creativity, especially in nuanced and complex topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. (5 marks)  \n",
    "\n",
    "**Problem Statement** \n",
    "Consider a biased coin that lands on heads with probability `q` and on tails with probability `1-q`. You keep flipping the coin until you get two consecutive heads. What is the expected number of flips required to achieve this? Express your answer as a function of `q`.  \n",
    "\n",
    "**Input Format:**  \n",
    "A single decimal number `q` (0 < `q` < 1), representing the probability of the coin landing on heads.  \n",
    "\n",
    "**Output Format:**  \n",
    "A mathematical expression representing the expected number of flips required to get two consecutive heads, as a function of `q`.  \n",
    "\n",
    "**Sample Inputs and Outputs**  \n",
    "- **Sample Input 1:** `q = 0.5`\n",
    "- **Sample Output 1:** `6`\n",
    "- **Explanation:** With a fair coin (`q = 0.5`), the expected number of flips to get two consecutive heads is 6.\n",
    "\n",
    "- **Sample Input 2:** `q = 0.75`\n",
    "- **Sample Output 2:** `2.6667`\n",
    "- **Explanation:** With a biased coin favoring heads (`q = 0.75`), the expected number of flips to get two consecutive heads is approximately 2.67.\n",
    "\n",
    "**Constraints**  \n",
    "`0 < q < 1`, i.e., the coin must be biased in favor of either heads or tails, but cannot be a certain outcome.\n",
    "\n",
    "**Solution:**  \n",
    "To solve the problem of finding the expected number of flips required to get two consecutive heads with a coin that lands on heads with probability \\( q \\) and tails with probability \\( 1-q \\), we can use the concept of expected value in probability theory.  \n",
    "\n",
    "The problem can be broken down into different states representing the outcomes of consecutive flips. Let's define:  \n",
    "- \\( E \\): Expected number of flips to get two consecutive heads.\n",
    "- \\( E_1 \\): Expected number of flips to get the first head.\n",
    "- \\( E_2 \\): Expected number of flips to get the second consecutive head after the first head.\n",
    "\n",
    "1. **Finding \\( E_1 \\):**\n",
    "   - The probability of getting heads on any flip is \\( q \\).\n",
    "   - The expected number of flips to get the first head is simply the reciprocal of this probability, \\( E_1 = 1/q \\).\n",
    "\n",
    "2. **Finding \\( E_2 \\):**\n",
    "   - Once we get the first head, there are two possibilities for the next flip:\n",
    "     - Heads with probability \\( q \\), which achieves our goal.\n",
    "     - Tails with probability \\( 1-q \\), after which we are back to our original state.\n",
    "   - The expected number of flips in this stage is \\( E_2 = 1*q + (1 + E)*(1-q) \\). The term \\( 1+E \\) accounts for the flip that just happened (either heads or tails) and the expected number of additional flips needed (i.e., \\( E \\)).\n",
    "\n",
    "3. **Total Expected Number of Flips \\( E \\):**\n",
    "   - Combining the two stages, we have \\( E = E_1 + E_2 \\).\n",
    "   - Substituting \\( E_1 \\) and \\( E_2 \\) gives \\( E = 1/q + 1*q + (1 + E)*(1-q) \\).\n",
    "\n",
    "4. **Solving for \\( E \\):**\n",
    "   - Rearranging the equation and solving for \\( E \\) gives the final expression for the expected number of flips.\n",
    "\n",
    "**Sample Calculation**  \n",
    "For \\( q = 0.5 \\) (a fair coin), the equation becomes:  \n",
    "- \\( E = 2 + 0.5 + (2 - E)*0.5 \\).\n",
    "- Solving this equation gives \\( E = 6 \\).\n",
    "\n",
    "For \\( q = 0.75 \\), the equation becomes:  \n",
    "- \\( E = 4/3 + 0.75 + ((4/3) + 1 - E)*0.25 \\).\n",
    "- Solving this equation gives \\( E â‰ˆ 2.6667 \\).  \n",
    "\n",
    "The solution's correctness is based on the fundamental principles of expected value in probability theory. By breaking down the process into distinct stages and analyzing the expected outcomes at each stage, we ensure a comprehensive calculation of the total expected number of flips. This approach, grounded in probability theory, provides a precise and logical solution to the problem.  \n",
    " \n",
    "**Reflection:** Reflecting on this task, ChatGPT's role in developing a new probability problem was invaluable, especially in maintaining the essence of the original concept while introducing a new angle. The challenge of ensuring the problem remained true to the principles of probability theory was significant. This experience highlighted the balance between leveraging AI assistance and applying my own understanding, deepening my skills in algorithmic problem design and solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. (5 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "Consider a two-player game represented by the following payoff matrix. Determine if there are any Nash equilibria in this game. A Nash equilibrium is a situation where no player can benefit by unilaterally changing their strategy, given the strategy of the other player.  \n",
    "\n",
    "             Strategy A   Strategy B  \n",
    "Strategy A    (3, 3)       (2, 4)\n",
    "Strategy B    (4, 2)       (1, 1)  \n",
    "In this matrix, the first number in each pair represents the payoff for Player 1, and the second number represents the payoff for Player 2. For example, if both players choose Strategy A, they both receive a payoff of 3.  \n",
    "\n",
    "**Input Format:**  \n",
    "A 2x2 matrix representing the payoffs for each combination of strategies.  \n",
    "\n",
    "**Output Format:**  \n",
    "Identification of any Nash equilibria in the given matrix and a brief explanation of why they are Nash equilibria.  \n",
    "\n",
    "**Sample Input:**  \n",
    "  Strategy A   Strategy B  \n",
    "  Strategy A    (3, 3)       (2, 4)  \n",
    "  Strategy B    (4, 2)       (1, 1)  \n",
    "\n",
    "**Sample Output:**  \n",
    "The game has one Nash equilibrium at (Strategy A, Strategy A) where both players receive a payoff of 3. Changing strategies unilaterally would not benefit either player.  \n",
    "\n",
    "**Constraints**  \n",
    "- The payoffs are assumed to be integers.\n",
    "- The strategies are limited to the ones provided in the matrix (two per player).  \n",
    "\n",
    "**Solution:**  \n",
    "To solve the problem of identifying Nash equilibria in the given payoff matrix, we need to analyze each player's best responses to the strategies of the other player. A Nash equilibrium occurs when each player's strategy is the best response to the other player's strategy.  \n",
    "\n",
    "**Payoff Matrix**\n",
    "           Strategy A   Strategy B  \n",
    "Strategy A    (3, 3)       (2, 4)  \n",
    "Strategy B    (4, 2)       (1, 1)  \n",
    "\n",
    "1. **Strategy A vs. Strategy A:** \n",
    "   - Player 1's payoff: 3\n",
    "   - Player 2's payoff: 3\n",
    "   - If Player 1 switches to Strategy B, their payoff becomes 4, which is better. Therefore, Strategy A is not Player 1's best response to Strategy A.\n",
    "   - If Player 2 switches to Strategy B, their payoff becomes 1, which is worse. Therefore, Strategy A is Player 2's best response to Strategy A.\n",
    "\n",
    "2. **Strategy A vs. Strategy B:** \n",
    "   - Player 1's payoff: 2\n",
    "   - Player 2's payoff: 4\n",
    "   - If Player 1 switches to Strategy B, their payoff becomes 1, which is worse. Therefore, Strategy A is Player 1's best response to Strategy B.\n",
    "   - If Player 2 switches to Strategy A, their payoff becomes 3, which is worse. Therefore, Strategy B is Player 2's best response to Strategy A.\n",
    "\n",
    "3. **Strategy B vs. Strategy A:** \n",
    "   - Player 1's payoff: 4\n",
    "   - Player 2's payoff: 2\n",
    "   - If Player 1 switches to Strategy A, their payoff becomes 3, which is worse. Therefore, Strategy B is Player 1's best response to Strategy A.\n",
    "   - If Player 2 switches to Strategy B, their payoff becomes 1, which is worse. Therefore, Strategy A is Player 2's best response to Strategy B.\n",
    "\n",
    "4. **Strategy B vs. Strategy B:** \n",
    "   - Player 1's payoff: 1\n",
    "   - Player 2's payoff: 1\n",
    "   - If Player 1 switches to Strategy A, their payoff becomes 2, which is better. Therefore, Strategy B is not Player 1's best response to Strategy B.\n",
    "   - If Player 2 switches to Strategy A, their payoff becomes 4, which is better. Therefore, Strategy B is not Player 2's best response to Strategy B.  \n",
    "\n",
    "Based on the analysis, the game has one Nash equilibrium at the combination (Strategy A, Strategy B). In this state, no player can unilaterally change their strategy for a better payoff. Player 1's best response to Player 2's Strategy B is Strategy A, and Player 2's best response to Player 1's Strategy A is Strategy B.  \n",
    "\n",
    "The solution's correctness relies on the definition of Nash equilibrium. By examining each player's payoffs and potential gains or losses from switching strategies, we can determine if the current strategy pair forms a Nash equilibrium. The analysis methodically considers each possible strategy combination and checks if both players are at their best responses to the other's strategy, ensuring that no Nash equilibrium is overlooked.  \n",
    " \n",
    "**Reflection:** Reflecting on the task of rephrasing and solving a game theory problem, ChatGPT's role was pivotal in generating a new but conceptually similar Nash equilibrium question. The challenge lay in altering the payoff matrix while preserving the essence of strategic decision-making inherent in game theory. ChatGPT effectively demonstrated its understanding and application of complex theoretical concepts in this context.  \n",
    "\n",
    "The solution phase highlighted the importance of clear and engaging presentation. Adopting a flowchart approach for analyzing Nash equilibria, inspired by ChatGPT's versatility, emphasized the need for clarity in explaining abstract concepts. This experience not only enhanced my understanding of problem design in algorithms but also underscored the balance between AI assistance and personal input in effective problem-solving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. (5 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "### New Question: Probability with Dice Rolls\n",
    "\n",
    "**Problem Statement:**\n",
    "Two dice are rolled successively. Determine the probabilities for the following events:\n",
    "(a) The first die shows a six, but the second does not.\n",
    "(b) At least one die shows an even number.\n",
    "(c) The dice show different numbers.\n",
    "(d) No more than one die shows a number less than three.\n",
    "\n",
    "### Input and Output Format:\n",
    "- **Input:** There is no input required as the problem deals with theoretical probability.\n",
    "- **Output:** Probabilities for each of the events listed above.\n",
    "\n",
    "### Sample Inputs and Outputs:\n",
    "- **Input:** N/A\n",
    "- **Output:**\n",
    "  - (a) Probability first die is six and second is not: P(A)\n",
    "  - (b) Probability at least one die is even: P(B)\n",
    "  - (c) Probability dice show different numbers: P(C)\n",
    "  - (d) Probability no more than one die shows a number less than three: P(D)\n",
    "\n",
    "### Constraints:\n",
    "- The dice are fair, with each side having an equal probability of being rolled.\n",
    "- The dice are rolled independently of each other.\n",
    "\n",
    "**Solution:**  \n",
    "### Explanation for the New Dice Probability Question Solution:\n",
    "\n",
    "The solution involves calculating the probabilities of various outcomes when rolling two dice successively. Here's a breakdown of each part:\n",
    "\n",
    "#### Event (a): First Die Shows a Six, but the Second Does Not\n",
    "- The probability of rolling a six on the first die is \\( \\frac{1}{6} \\).\n",
    "- The probability of not rolling a six on the second die is \\( \\frac{5}{6} \\).\n",
    "- Since the dice rolls are independent, the combined probability is the product of the two individual probabilities: \\( \\frac{1}{6} \\times \\frac{5}{6} \\).\n",
    "\n",
    "#### Event (b): At Least One Die Shows an Even Number\n",
    "- The probability of not rolling an even number on one die is \\( \\frac{1}{2} \\).\n",
    "- The probability of not rolling an even number on both dice is \\( \\frac{1}{2} \\times \\frac{1}{2} \\).\n",
    "- To find the probability of at least one die showing an even number, subtract the above probability from 1 (complement rule): \\( 1 - \\frac{1}{2} \\times \\frac{1}{2} \\).\n",
    "\n",
    "#### Event (c): The Dice Show Different Numbers\n",
    "- The probability that both dice show the same number is \\( \\frac{1}{6} \\) since there are six possible pairs where both dice are the same.\n",
    "- The probability of rolling different numbers on both dice is the complement of the above: \\( 1 - \\frac{1}{6} \\).\n",
    "\n",
    "#### Event (d): No More Than One Die Shows a Number Less Than Three\n",
    "- There are two outcomes to consider here:\n",
    "  - Both dice show a number less than three.\n",
    "  - One die shows a number less than three, and the other does not.\n",
    "- The probability of rolling a number less than three on a die is \\( \\frac{2}{6} \\) or \\( \\frac{1}{3} \\).\n",
    "- The probability of rolling a number less than three on both dice is \\( \\frac{1}{3} \\times \\frac{1}{3} \\).\n",
    "- The probability of one die showing less than three and the other not is \\( 2 \\times \\frac{1}{3} \\times \\frac{2}{3} \\) (considering both dice).\n",
    "- The combined probability for event (d) is the sum of probabilities for the two outcomes, minus the probability of both dice showing a number less than three.\n",
    "\n",
    "The Python code executes these calculations, which are straightforward applications of the basic probability principles and the independence of the dice rolls. The solution uses the complement rule effectively, especially for events where it's easier to calculate the probability of the opposite outcome and then subtract from one to get the desired probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Event a): Probability is 0.1388888888888889\n",
      "(Event b): Probability is 0.75\n",
      "(Event c): Probability is 0.8333333333333334\n",
      "(Event d): Probability is 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "def dice_probability():\n",
    "    outcomes = 6 * 6  # Total number of outcomes for two dice\n",
    "    # Event (a)\n",
    "    prob_a = (1/6) * (5/6)\n",
    "    # Event (b)\n",
    "    prob_b = 1 - (1/2) * (1/2)\n",
    "    # Event (c)\n",
    "    prob_c = 1 - (1/6)\n",
    "    # Event (d)\n",
    "    prob_d = 1 - (1/6) * (1/6) - (5/6) * (1/6)\n",
    "\n",
    "    return {\n",
    "        'a': prob_a,\n",
    "        'b': prob_b,\n",
    "        'c': prob_c,\n",
    "        'd': prob_d\n",
    "    }\n",
    "\n",
    "# Calculate probabilities\n",
    "probabilities = dice_probability()\n",
    "\n",
    "# Output the probabilities\n",
    "for event, prob in probabilities.items():\n",
    "    print(f\"(Event {event}): Probability is {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection:** Creating this new question based on the original card-drawing probability scenario, I had to shift the context from a deck of cards to dice rolls while preserving the concept of calculating probabilities for various events. The challenge was to ensure that the newly crafted problem was analogous to the original, maintaining the essence of independent probability events without direct translation. This task has enhanced my understanding of probability theory and its versatile application across different scenarios.  \n",
    "Through writing the Python code, I learned the importance of clear logic and computational accuracy when solving probability problems. The use of a simple code to calculate theoretical probabilities demonstrates how computational tools can be effectively used to aid in understanding and solving mathematical problems. The assistance from AI, in this case, validated the approach and ensured the correctness of the solution, showcasing the genuine utility of such tools in educational contexts. This reflection process has solidified my grasp of the underlying principles and has been a meaningful part of the learning experience.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. (5 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "Analyze and discuss the following aspects of Las Vegas and Monte Carlo algorithms:  \n",
    "(A) (2 points) Evaluate whether a Las Vegas algorithm can be modified to have a bounded runtime while maintaining its probabilistic correctness guarantees.  \n",
    "(B) (3 points) Assess the feasibility of transforming a Monte Carlo algorithm to guarantee an exact solution, while retaining its original performance characteristics.  \n",
    "\n",
    "**Input Format:**  \n",
    "There is no specific input for this theoretical question.  \n",
    "\n",
    "**Output Format:**  \n",
    "A written argument or proof addressing the two parts of the question.  \n",
    "\n",
    "**Sample Input:**  \n",
    "Not applicable for a theoretical question.  \n",
    "\n",
    "**Sample Output:**  \n",
    "  - (A) A discussion on whether a Las Vegas algorithm can be adapted to have a bounded runtime without losing its probabilistic correctness.\n",
    "  - (B) An analysis of whether it's feasible to alter a Monte Carlo algorithm to always produce an exact solution while keeping its performance efficiency.\n",
    "\n",
    "**Constraints**  \n",
    "- The discussion should be grounded in theoretical computer science, specifically in the domains of algorithm design and analysis.\n",
    "- The arguments should reference the inherent characteristics of Las Vegas and Monte Carlo algorithms.\n",
    "\n",
    "**Solution:**  \n",
    "To address the reformulated question on Las Vegas and Monte Carlo algorithms, let's analyze each part of the question based on algorithmic theory and principles.  \n",
    "\n",
    "**Part A:** Modifying a Las Vegas Algorithm to Have Bounded Runtime  \n",
    "1. **Las Vegas Algorithms:** These are randomized algorithms that always produce the correct result or report failure. They have variable runtime, but the result, when they terminate, is always correct.  \n",
    "2. **Bounded Runtime Adaptation:**  \n",
    "   - To modify a Las Vegas algorithm to have a bounded runtime, one could introduce a limit on the number of iterations or the total execution time.\n",
    "   - If the algorithm reaches this limit without finding a solution, it could either return a failure or the best solution found within the constraint.  \n",
    "3. **Impact on Probabilistic Correctness:**  \n",
    "   - By bounding the runtime, we are essentially introducing a trade-off between runtime and the probability of finding the correct solution.\n",
    "   - The algorithm may still maintain a high probability of correctness but won't guarantee it in every execution, as it might terminate prematurely due to the bound.  \n",
    "\n",
    "**Part B:** Transforming a Monte Carlo Algorithm to Guarantee an Exact Solution  \n",
    "1. **Monte Carlo Algorithms:** These algorithms have a bounded runtime but may only produce a correct result with some probability. They are typically used for problems where an approximate solution is acceptable.  \n",
    "2. **Guaranteeing Exact Solution:**  \n",
    "   - To modify a Monte Carlo algorithm to guarantee an exact solution, one would need to alter its probabilistic components to ensure correctness.\n",
    "   - This could involve increasing the sample size, iterating until a certain confidence level is achieved, or employing a hybrid approach with deterministic methods.\n",
    "3. **Impact on Performance Characteristics:**  \n",
    "   - Such modifications would likely impact the algorithmâ€™s performance, potentially increasing its runtime or computational complexity.\n",
    "   - The challenge is to retain the original performance characteristics while enhancing accuracy, which may not always be feasible, especially for complex or NP-hard problems.\n",
    "\n",
    "**Conclusion**  \n",
    "- **Part A:** It is possible to modify a Las Vegas algorithm to have a bounded runtime, but this may affect its probabilistic correctness guarantees.  \n",
    "- **Part B:** Transforming a Monte Carlo algorithm to guarantee an exact solution is challenging and may impact its original performance characteristics, making it less efficient or practical for certain applications.  \n",
    "\n",
    "The analysis is grounded in the fundamental definitions and characteristics of Las Vegas and Monte Carlo algorithms. By considering the inherent properties of these algorithms and the implications of modifying them, the solution provides a theoretical but realistic assessment of the possibilities and limitations inherent in such transformations.  \n",
    " \n",
    "**Reflection:** In addressing the task of formulating and solving a complex question about Las Vegas and Monte Carlo algorithms, ChatGPT's assistance was instrumental. It helped me frame a question that not only aligned with the original's spirit but also added a fresh perspective. The challenge was to delve into the nuanced differences and potential modifications of these algorithm types while maintaining their fundamental properties. This task enlightened me on the intricacies of algorithm design, specifically the delicate balance between an algorithm's theoretical purity and practical adaptability.  \n",
    "\n",
    "ChatGPT's role was crucial in guiding the theoretical analysis, yet it was clear that a deep personal understanding of algorithmic principles was essential to craft a coherent and accurate response. This experience underscored the value of AI tools like ChatGPT as supplements in the learning process, providing foundational guidance but ultimately leaving the critical thinking and synthesis to the individual.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. (5 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "Consider the Fibonacci sequence algorithm, a classic example in computer science for demonstrating recursion and its efficiency. The Fibonacci sequence is defined such that each number is the sum of the two preceding ones, starting from 0 and 1.  \n",
    "\n",
    "The algorithm in pseudocode to calculate the nth Fibonacci number is as follows:  \n",
    "\n",
    "int fibonacci(int n){  \n",
    "    if(n <= 1)  \n",
    "        return n;  \n",
    "    else  \n",
    "        return fibonacci(n-1) + fibonacci(n-2);  \n",
    "}  \n",
    "\n",
    "- (A) **(3 points)** Write a recurrence relation for the Fibonacci sequence algorithm. Note: You can express the recurrence relation in the form T(n) = T(n-a) + T(n-b) + c, where a and b are constants and c represents constant time operations.  \n",
    "- (B) **(2 points)** Provide an expression for the runtime T(n) if your Fibonacci algorithm recurrence can be analyzed with common algorithm analysis techniques (like the Master Theorem or others). Explain your reasoning.  \n",
    "\n",
    "**Input Format:**  \n",
    "An integer `n`, representing the nth number in the Fibonacci sequence.  \n",
    "\n",
    "**Output Format:**  \n",
    "The nth Fibonacci number.  \n",
    "\n",
    "**Sample Input:** `5`  \n",
    "**Sample Output:** `5` (as the Fibonacci sequence up to the 5th number is 0, 1, 1, 2, 3, 5)  \n",
    "\n",
    "**Constraints**\n",
    "- The Fibonacci sequence algorithm should be implemented recursively.\n",
    "- The analysis should focus on the computational complexity of the recursive approach.  \n",
    "\n",
    "**Solution:**  \n",
    "To address the new question about the Fibonacci sequence algorithm, let's analyze its recurrence relation and compute its runtime complexity.  \n",
    "\n",
    "**Part A:** Recurrence Relation for the Fibonacci Sequence Algorithm  \n",
    "1. **Fibonacci Algorithm Analysis:**\n",
    "   - The Fibonacci algorithm calls itself recursively to calculate the (n-1)th and (n-2)th Fibonacci numbers and then adds them together.\n",
    "   - The base cases are when `n <= 1`, where the function returns `n`.  \n",
    "2. **Recurrence Relation:**  \n",
    "   - The recurrence relation for this algorithm is \\( T(n) = T(n-1) + T(n-2) + O(1) \\).\n",
    "   - The \\( O(1) \\) term represents the constant time operations for addition and the base case check.  \n",
    "\n",
    "**Part B:** Runtime Expression  \n",
    "1. **Runtime Analysis:**  \n",
    "   - The Fibonacci sequence algorithm's recurrence relation does not fit neatly into the Master Theorem due to the two recursive calls.\n",
    "   - However, its runtime can be analyzed by examining the depth and breadth of its recursion tree.\n",
    "2. **Expression for Runtime:**  \n",
    "   - The depth of the recursion tree is proportional to `n`.\n",
    "   - At each level, the number of nodes roughly doubles (each call spawns two more calls).\n",
    "   - Therefore, the total number of nodes (and thus the total amount of work) is approximately \\( O(2^n) \\).\n",
    "   - Thus, the runtime T(n) for the recursive Fibonacci algorithm is exponential, \\( T(n) = O(2^n) \\).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5th Fibonacci number is: 5\n"
     ]
    }
   ],
   "source": [
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "# Example usage\n",
    "n = 5\n",
    "print(f\"The {n}th Fibonacci number is: {fibonacci(n)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof of Correctness**  \n",
    "The correctness of the Fibonacci algorithm is based on the well-established definition of the Fibonacci sequence. Each number is indeed the sum of the two preceding numbers, and the base cases for `n = 0` and `n = 1` are accurately handled. The exponential runtime complexity is a direct consequence of the recursive calls structure, as each call generates two more calls, leading to a rapid growth in the number of operations required.  \n",
    " \n",
    "**Reflection:** Reflecting on the task of developing and solving a question about the Fibonacci sequence, ChatGPT's assistance was crucial in formulating a problem that mirrored the essence of the original Euclid's algorithm question. The challenge lay in maintaining the core concept of algorithmic analysis while shifting the focus to a different algorithm. Through this process, I gained deeper insights into how the specific structure of an algorithm, such as the recursive nature of the Fibonacci sequence, significantly impacts its computational complexity.  \n",
    "\n",
    "ChatGPT's guidance in breaking down the Fibonacci algorithm and analyzing its recursive calls enhanced my understanding of algorithmic efficiency and its practical implications. The experience of translating theoretical analysis into a Python implementation further solidified my grasp of the concepts. This task underscored the value of AI tools like ChatGPT in assisting with educational and technical tasks, offering foundational guidance while encouraging personal engagement and understanding in complex topics like algorithms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. (5 marks)  \n",
    "\n",
    "**Problem Statement** \n",
    "Consider a graph \\( G = (V, E) \\) where each node can be either active or inactive. The state of each node is determined randomly: a node is active with probability \\( q \\) and inactive with probability \\( 1-q \\). In this graph, an active node can only join a special set \\( T \\) if none of its adjacent nodes (i.e., nodes it shares an edge with) are also active.  \n",
    "\n",
    "Design a randomized algorithm based on this concept and calculate the expected size of the set \\( T \\) when \\( q \\) is set to a specific value, say 0.3. Assume that each node in the graph has exactly \\( k \\) neighbors.  \n",
    "\n",
    "**Input Format:**   \n",
    "The inputs are the graph \\( G \\), the probability \\( q \\) of a node being active, and the number \\( k \\) of neighbors for each node.  \n",
    "\n",
    "**Output Format:**  \n",
    "An expression or formula representing the expected size of the set \\( T \\).  \n",
    "\n",
    "**Sample Input:**  \n",
    "A graph \\( G \\) with each node having 3 neighbors, and \\( q = 0.3 \\).  \n",
    "\n",
    "**Sample Output:**  \n",
    "An expression for the expected size of \\( T \\) based on the provided graph characteristics and \\( q \\) value.  \n",
    "\n",
    "**Constraints**  \n",
    "- The graph \\( G \\) is undirected and simple (no loops or multiple edges).\n",
    "- Each node in the graph has exactly \\( k \\) neighbors.\n",
    "- \\( 0 < q < 1 \\).  \n",
    "\n",
    "**Solution:** \n",
    "To solve the problem of calculating the expected size of the set \\( T \\) in a graph \\( G \\) where each node has a probability \\( q \\) of being active, we need to use probability theory and consider the structure of the graph.  \n",
    "\n",
    "Given that each node in \\( G \\) has \\( k \\) neighbors and becomes active with probability \\( q \\), a node can join the set \\( T \\) if and only if it is active and all its \\( k \\) neighbors are inactive. The probability of a neighbor being inactive is \\( 1-q \\).  \n",
    "1. **Probability of a Node Joining \\( T \\):**  \n",
    "   - A node joins \\( T \\) if it is active *and* all its \\( k \\) neighbors are inactive.\n",
    "   - The probability of a node being active is \\( q \\).\n",
    "   - The probability of each of its \\( k \\) neighbors being inactive is \\( (1-q) \\).\n",
    "   - Therefore, the probability of a node joining \\( T \\) is \\( q \\times (1-q)^k \\).\n",
    "2. **Expected Size of \\( T \\):**\n",
    "   - Let \\( n \\) be the total number of nodes in \\( G \\).\n",
    "   - The expected size of \\( T \\) is the sum of the probabilities of each node joining \\( T \\).\n",
    "   - Since each node joins \\( T \\) independently, the expected size of \\( T \\) is \\( n \\times q \\times (1-q)^k \\).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected size of set T is: 10.289999999999997\n"
     ]
    }
   ],
   "source": [
    "def expected_size_of_T(n, k, q):\n",
    "    return n * q * ((1-q) ** k)\n",
    "\n",
    "# Example usage\n",
    "n = 100  # number of nodes in the graph\n",
    "k = 3    # each node has 3 neighbors\n",
    "q = 0.3  # probability of a node being active\n",
    "\n",
    "expected_size = expected_size_of_T(n, k, q)\n",
    "print(f\"The expected size of set T is: {expected_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected size of the set \\( T \\) in a graph with the given structure and node activation probability can be calculated using the derived formula. This solution highlights the application of basic probability principles to a graph-theoretic problem, illustrating how randomized algorithms can provide insights into complex problems.\n",
    "\n",
    "**Proof of Correctness**  \n",
    "The solution is grounded in probabilistic reasoning, considering the independent events of each node being active and its neighbors being inactive. The multiplication of probabilities for independent events and the scaling by the total number of nodes \\( n \\) ensure a comprehensive and accurate calculation of the expected set size. This approach is a standard method in probabilistic analysis and is widely applicable in similar problems in graph theory and algorithm design.  \n",
    " \n",
    "**Reflection:** Working on this graph-theoretic problem with ChatGPT's assistance was enlightening. The tool helped me frame a new problem that mirrored the complexity and nature of the original one about the randomized algorithm for finding a maximum independent set. The challenge was to maintain the essence of probabilistic algorithm design while introducing a different graph structure and objective. This task deepened my understanding of algorithm design, especially in probabilistic contexts, and highlighted the importance of careful problem formulation.  \n",
    "\n",
    "Creating a solution, particularly formulating the probability expression and translating it into a Python code, was a blend of theoretical knowledge and practical application. ChatGPT's role was integral in guiding the theoretical aspects, but applying these concepts in a meaningful and accurate way required my active engagement and understanding. This experience demonstrated the value of AI tools like ChatGPT in educational contexts, where they can provide foundational support but still necessitate critical thinking and problem-solving skills from the learner.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11. (5 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "Apply the Merge Sort algorithm to arrange the following list of integers in ascending order. Analyze the algorithm's complexity.  \n",
    "- (A) Sort the list using Merge Sort. Show your work.\n",
    "- (B) Write the recurrence relations for the worst case and average case of Merge Sort.\n",
    "- (C) Derive an expression for the runtime T(n) for both the worst-case and average-case scenarios of Merge Sort.  \n",
    "\n",
    "**Input Format:**  \n",
    "A list of integers (e.g., [18, 7, 25, 3, 9, 26, 15, 4]).  \n",
    "\n",
    "**Output Format:**  \n",
    "(A) A sorted list of integers.  \n",
    "(B & C) Mathematical expressions or formulas.  \n",
    "\n",
    "**Sample Input:** [18, 7, 25, 3, 9, 26, 15, 4]  \n",
    "\n",
    "**Sample Output:**  \n",
    "(A) [3, 4, 7, 9, 15, 18, 25, 26]  \n",
    "(B & C) Specific recurrence relations and runtime expressions.  \n",
    "\n",
    "**Constraints:**  \n",
    "The list should be sorted using the Merge Sort algorithm.  \n",
    "\n",
    "**Solution:**  \n",
    "**Part A:** Sorting Using Merge Sort  \n",
    "\n",
    "**Given List:** [18, 7, 25, 3, 9, 26, 15, 4]  \n",
    "\n",
    "**Merge Sort Steps:**  \n",
    "1. Divide the list into halves until each sublist has one element.\n",
    "2. Merge sublists to produce new sorted sublists until there is only one sublist remaining.  \n",
    "\n",
    "**Sorting Process:**  \n",
    "- Step 1: Divide [18, 7, 25, 3, 9, 26, 15, 4] into two halves.\n",
    "- Step 2: Keep dividing until you get individual elements.\n",
    "- Step 3: Start merging and sorting these elements step by step.\n",
    "- Final Step: The merged and sorted list will be [3, 4, 7, 9, 15, 18, 25, 26].  \n",
    "\n",
    "**Part B:** Recurrence Relations  \n",
    "- **Worst Case:** The worst-case recurrence relation for Merge Sort is \\( T(n) = 2T(n/2) + O(n) \\).\n",
    "- **Average Case:** The average case is similar to the worst case for Merge Sort, so it's also \\( T(n) = 2T(n/2) + O(n) \\).  \n",
    "\n",
    "**Part C:** Runtime Expression  \n",
    "- **Master Theorem Application:** Both cases follow the Master Theorem's second case.\n",
    "- **Runtime Complexity:** The runtime for both cases is \\( T(n) = O(n \\log n) \\).  \n",
    "\n",
    "**Reflection:** Working on these algorithmic problems with ChatGPT has been an insightful journey. ChatGPT was particularly helpful in formulating a new sorting question that adhered to the conceptual basis of the original quicksort problem. The challenge was to preserve the essence of algorithm analysis while introducing a different algorithm (Merge Sort), which ChatGPT navigated skillfully.  \n",
    "\n",
    "The solution phase, especially breaking down the Merge Sort process and discussing its complexity, was enriching. ChatGPT provided foundational guidance, but the task of translating theoretical understanding into a structured solution required a deeper personal engagement with the subject. This experience was a testament to the value of AI tools like ChatGPT in educational settings. They offer significant assistance but ultimately necessitate active learning and critical thinking from the user.  \n",
    "\n",
    "From this task, I gleaned meaningful insights into problem design in the realm of algorithms. It became evident that a well-structured problem not only challenges the understanding of an algorithm's mechanics but also its underlying principles and implications. The balance between AI-assisted learning and personal exploration in such complex topics was a key takeaway, underscoring the nuanced role of tools like ChatGPT in the broader educational landscape.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12. (5 marks)  \n",
    "\n",
    "**Problem Statement** In a simplified auction system with n unique bidders, calculate the expected number of times the highest bid is updated.    \n",
    "\n",
    "**Input Format:** A list of bid values (e.g., [22, 33, 11]) and the number of bidders n.  \n",
    "\n",
    "**Output Format:** A mathematical expression or number representing the expected updates to the highest bid.  \n",
    "\n",
    "**Sample Inputs and Outputs:**  \n",
    "Input: Bid values [22, 33, 11], n = 3  \n",
    "Output: Expected number of updates (e.g., 2)  \n",
    "\n",
    "**Constraints:**  \n",
    "- Each bid value is unique and a positive integer.  \n",
    "- The order of bidders is random.  \n",
    "\n",
    "**Solution:**  \n",
    "1. **Understanding the Process:**\n",
    "   - Each bidder has a unique bid and the bids are processed in a random order.\n",
    "   - `b*` starts at 0 and is updated to a bidder's bid if it's the highest seen so far.  \n",
    "2. **Expected Number of Updates:**\n",
    "   - The first bid always updates `b*`.\n",
    "   - Each subsequent bid has a 1 in `n` chance of being the highest seen so far.\n",
    "   - Therefore, the expected number of times `b*` is updated for each of the `n` bidders is `1/n`.  \n",
    "3. **Total Expected Updates:**  \n",
    "   - The expected total number of updates is the sum of the expected updates for each bidder.\n",
    "   - Thus, the total is `1 + 1/2 + 1/3 + ... + 1/n`.\n",
    "   - This is the `n`th harmonic number, which can be approximated by `ln(n) + gamma` (where `gamma` is the Euler-Mascheroni constant, approximately 0.577).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8333333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expected_bid_updates(n):\n",
    "    \"\"\"\n",
    "    Calculate the expected number of times the highest bid is updated.\n",
    "    :param n: Number of bidders\n",
    "    :return: Expected number of updates\n",
    "    \"\"\"\n",
    "    expected_updates = sum([1/i for i in range(1, n + 1)])\n",
    "    return expected_updates\n",
    "\n",
    "# Example usage\n",
    "n = 3\n",
    "expected_updates = expected_bid_updates(n)\n",
    "expected_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection:** Working on this auction system problem with the assistance of ChatGPT has been a multifaceted learning experience. ChatGPT played a crucial role in restructuring a new problem around the concept of probability and expectation in a bidding scenario. The key challenge was to ensure that the new problem retained the essence of the original one, focusing on understanding random events and their outcomes. This was adeptly managed, showcasing the tool's capability in adapting and presenting complex concepts in a comprehensible manner.  \n",
    "\n",
    "The solution phase, particularly the probabilistic analysis of the auction system, was enlightening. While ChatGPT laid the groundwork, translating this into a coherent solution that accurately represented the expected outcomes required a deeper dive into probabilistic reasoning. This task underscored the importance of a strong foundational understanding of probability in algorithm design and the invaluable role of tools like ChatGPT in guiding through complex problem-solving processes.  \n",
    "\n",
    "This experience has enhanced my understanding of how to design and analyze problems, especially those involving random processes. The insights I gained on the interplay between algorithm design, probability theory, and practical application were profound. It highlighted that while AI tools like ChatGPT can provide significant assistance, the onus of in-depth understanding and application remains on the learner, fostering a balanced approach to AI-assisted education.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q13. (5 marks)  \n",
    "\n",
    "**Problem Statement** In a distributed computing environment, you have developed an algorithm to distribute \\( m \\) computing tasks randomly across \\( n \\) servers.  \n",
    "- (A) Calculate the expected number of tasks each server will handle.\n",
    "- (B) Determine the probability that a server handles at least 150% of the average load.\n",
    "- (C) Estimate the probability that a server ends up with no tasks.  \n",
    "\n",
    "**Input Format:** Two integers \\( m \\) (number of tasks) and \\( n \\) (number of servers).  \n",
    "\n",
    "**Output Format:**  \n",
    "- (A) Average number of tasks per server.\n",
    "- (B & C) Probabilities expressed as percentages or decimal fractions.  \n",
    "\n",
    "**Sample Inputs and Outputs:**  \n",
    "- **Input:** 1000 tasks, 50 servers  \n",
    "- **Output:**  \n",
    "  - (A) 20 tasks per server\n",
    "  - (B) Probability of handling at least 30 tasks\n",
    "  - (C) Probability of handling no tasks\n",
    "\n",
    "**Constraints:**  \n",
    "- Tasks are distributed independently and randomly.\n",
    "- \\( m \\) and \\( n \\) are positive integers.  \n",
    "\n",
    "**Solution:**  \n",
    "**Part A:** Expected Number of Jobs Per Server  \n",
    "1. **Analysis:**\n",
    "   - If \\( m \\) jobs are distributed randomly among \\( n \\) servers, each job has a \\( \\frac{1}{n} \\) chance of being assigned to any particular server.\n",
    "   - Therefore, the expected number of jobs per server is the total number of jobs \\( m \\) times the probability of any job being assigned to a particular server.  \n",
    "2. **Expected Jobs Per Server:**\n",
    "   - The expected number of jobs per server is \\( \\frac{m}{n} \\).  \n",
    "\n",
    "**Part B:** Probability of Server Getting Twice the Average Load  \n",
    "1. **Analysis:**  \n",
    "   - This is a problem of binomial probability where we want to find the probability of a server getting at least \\( 2 \\times \\frac{m}{n} \\) jobs.\n",
    "   - The probability of this happening can be calculated using the binomial distribution formula.\n",
    "2. **Probability Calculation:**  \n",
    "   - We would calculate the sum of probabilities of a server getting \\( k \\) jobs for all \\( k \\geq 2 \\times \\frac{m}{n} \\).\n",
    "\n",
    "**Part C:** Probability of Server Getting No Load  \n",
    "1. **Analysis:**  \n",
    "   - The probability of a server getting no load is the probability of all \\( m \\) jobs being assigned to other servers.\n",
    "2. **Probability Calculation:**  \n",
    "   - The probability for each job not being assigned to a particular server is \\( 1 - \\frac{1}{n} \\).\n",
    "   - Therefore, the probability of no job being assigned to a particular server is \\( \\left(1 - \\frac{1}{n}\\right)^m \\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected jobs per server: 20.0\n",
      "Probability of a server getting at least twice the average load: 4.339875894746395e-05\n",
      "Probability of a server getting no load: 1.6829673572159252e-09\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "def expected_jobs_per_server(m, n):\n",
    "    return m / n\n",
    "\n",
    "def probability_high_load(m, n, threshold):\n",
    "    prob = 0\n",
    "    for k in range(threshold, m + 1):\n",
    "        prob += binom.pmf(k, m, 1/n)\n",
    "    return prob\n",
    "\n",
    "def probability_no_load(m, n):\n",
    "    return (1 - 1/n)**m\n",
    "\n",
    "# Example usage\n",
    "m = 1000  # total jobs\n",
    "n = 50    # total servers\n",
    "\n",
    "# Expected jobs per server\n",
    "expected_jobs = expected_jobs_per_server(m, n)\n",
    "\n",
    "# Probability of getting twice the average load\n",
    "threshold = int(2 * expected_jobs)\n",
    "high_load_prob = probability_high_load(m, n, threshold)\n",
    "\n",
    "# Probability of getting no load\n",
    "no_load_prob = probability_no_load(m, n)\n",
    "\n",
    "print(f\"Expected jobs per server: {expected_jobs}\")\n",
    "print(f\"Probability of a server getting at least twice the average load: {high_load_prob}\")\n",
    "print(f\"Probability of a server getting no load: {no_load_prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection:** Reflecting on the task of addressing Q3, a problem about load distribution in a distributed computing environment, I found ChatGPT's assistance integral in shaping the approach and solution. The task was to translate a theoretical probability scenario into a practical computational problem. ChatGPT's role was pivotal in guiding the structuring of the problem, especially in breaking down the complex probabilistic concepts into manageable parts. One of the challenges was ensuring that the problem retained the essence of its theoretical roots while being framed in a way that is accessible and computationally solvable. This required a balance between theoretical accuracy and practical applicability.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q14. (5 marks)  \n",
    "\n",
    "**Problem Statement** Consider an algorithm that iteratively adjusts the values of a list of numbers until a certain condition is met. Does this iterative adjustment algorithm always terminate?  \n",
    "\n",
    "**Input Format:** N/A (Theoretical question).  \n",
    "\n",
    "**Output Format:** A written explanation discussing the termination conditions of the algorithm.  \n",
    "\n",
    "**Sample Inputs and Outputs:**  \n",
    "- **Input:** N/A  \n",
    "- **Output:** Explanation of whether the algorithm terminates and under what conditions.  \n",
    "\n",
    "**Constraints:**  \n",
    "- The problem is theoretical and does not require specific input data.  \n",
    "\n",
    "**Solution:**  \n",
    "1. **Algorithm Description:** \n",
    "   - A state-flipping algorithm iteratively adjusts the values of a list of numbers until a certain condition is met.\n",
    "   - For the algorithm to terminate, it must reach a state where no further adjustments are required according to its condition.\n",
    "2. **Termination Conditions:**\n",
    "   - If the algorithm is designed with a well-defined termination condition (e.g., reaching a particular state, or no further changes possible), then it will terminate.\n",
    "   - If the algorithm lacks such a condition or has a possibility of entering an infinite loop (e.g., values keep flipping without reaching a stable state), it may not terminate.\n",
    "3. **General Approach to Ensure Termination:**\n",
    "   - Introduce a condition that is guaranteed to be met after a finite number of steps.\n",
    "   - Implement safeguards against infinite loops, such as setting a maximum number of iterations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final state: [5, 4, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "def state_flipping_algorithm(values, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    A sample state-flipping algorithm that terminates either when no changes are made or a max iteration limit is reached.\n",
    "    :param values: List of numbers to be adjusted.\n",
    "    :param max_iterations: Maximum number of iterations to prevent infinite loops.\n",
    "    :return: Adjusted list of numbers.\n",
    "    \"\"\"\n",
    "    iteration = 0\n",
    "    while iteration < max_iterations:\n",
    "        changes_made = False\n",
    "        # Sample condition: Flip state if a value is less than its next value.\n",
    "        for i in range(len(values) - 1):\n",
    "            if values[i] < values[i + 1]:\n",
    "                values[i], values[i + 1] = values[i + 1], values[i]  # Swap values\n",
    "                changes_made = True\n",
    "\n",
    "        if not changes_made:\n",
    "            break  # Terminate if no changes are made\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    return values\n",
    "\n",
    "# Example usage\n",
    "values = [4, 2, 5, 1, 3]\n",
    "result = state_flipping_algorithm(values)\n",
    "print(\"Final state:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code represents a simple state-flipping algorithm with a clear termination condition. The algorithm terminates when either no changes are made in a pass through the list or a maximum number of iterations is reached, thus ensuring that it always terminates.\n",
    " \n",
    "**Reflection:** Reflecting on the task of analyzing the termination of a state-flipping algorithm (Q4), I found the guidance from ChatGPT to be highly valuable. The challenge in this task was not just to determine if a given algorithm terminates, but to conceptualize a state-flipping algorithm that would illustrate the termination conditions effectively. ChatGPT played a crucial role in breaking down the abstract concept into a tangible example, assisting in designing a simple yet illustrative algorithm.  \n",
    "One of the key challenges was ensuring that the problem and its solution stayed true to the spirit of algorithmic analysis, particularly focusing on termination conditions and infinite loops. Crafting the Python code to demonstrate these concepts required careful consideration of algorithm design principles. This task deepened my understanding of the importance of well-defined termination criteria in algorithms to prevent non-termination scenarios.  \n",
    "Through this exercise, I gained insights into the subtleties of algorithm design, especially in ensuring robustness and termination. ChatGPT's role was instrumental in providing the foundational structure and guiding principles, but the task of translating these into a practical implementation demanded a thoughtful approach and a solid grasp of algorithmic concepts. This experience highlighted the value of AI tools like ChatGPT in the learning process, where they serve as effective aids in exploring complex topics, yet the onus of deep understanding and application lies with the learner.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q15. (5 marks)  \n",
    "\n",
    "**Problem Statement** What is the probability of getting at least three tails when flipping five coins?  \n",
    "\n",
    "**Input Format:** N/A (Theoretical question based on a probability scenario).  \n",
    "\n",
    "**Output Format:** The probability expressed as a percentage or decimal fraction.  \n",
    "\n",
    "**Sample Input:** N/A  \n",
    "\n",
    "**Sample Output:** Probability of getting at least three tails in five coin flips.  \n",
    "\n",
    "**Constraints:**  \n",
    "- Each coin flip is independent and has two possible outcomes: heads or tails.\n",
    "- The probability of heads or tails in each flip is equal (0.5).  \n",
    "\n",
    "**Solution:**  \n",
    "\n",
    "**Probability Calculation:**\n",
    "  - Each coin flip has a 0.5 probability of landing tails.\n",
    "  - The probability of getting tails in all four flips (and thus no heads) is \\( 0.5^4 \\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of getting no heads in 4 coin flips is: 0.0625\n"
     ]
    }
   ],
   "source": [
    "def probability_no_heads(num_flips):\n",
    "    \"\"\"\n",
    "    Calculate the probability of getting exactly no heads after a certain number of coin flips.\n",
    "    :param num_flips: Number of coin flips\n",
    "    :return: Probability of getting no heads\n",
    "    \"\"\"\n",
    "    # Probability of getting tails in a single flip is 0.5\n",
    "    # Probability of getting tails in all flips is 0.5 raised to the power of num_flips\n",
    "    return 0.5 ** num_flips\n",
    "\n",
    "# Example usage for flipping four coins\n",
    "num_flips = 4\n",
    "probability = probability_no_heads(num_flips)\n",
    "print(f\"The probability of getting no heads in {num_flips} coin flips is: {probability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** The probability of getting no heads in four coin flips is \\( 0.0625 \\) or 6.25%.  \n",
    "This solution and Python code succinctly calculate the probability of a specific outcome in a series of independent events (coin flips), demonstrating the application of basic probability principles.  \n",
    "\n",
    "**Reflection:** Reflecting on the Q5 task about probability in coin flipping, I found ChatGPT's guidance crucial in formulating a clear problem statement and directing me towards the appropriate method for probability calculation. The main challenge was to ensure accuracy and simplicity in conveying the principles of probability theory.  \n",
    "\n",
    "The creation of the Python code was straightforward but highlighted the need for precision in algorithmic problem-solving. This task reinforced my understanding of probability fundamentals and their application in algorithms. ChatGPT served as a valuable tool, offering essential support while emphasizing the importance of active engagement and critical thinking in problem-solving. This experience underscored the importance of clear problem formulation in enhancing the understanding of core algorithmic concepts.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16. (5 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "**New Question Based on Q1:**\n",
    "\n",
    "### Problem Statement:\n",
    "Implement a randomized algorithm to select an approximate median from a dataset of integers. Use the median of randomly sampled elements as an estimate and determine the confidence interval around this median estimate using the sample standard deviation.\n",
    "\n",
    "### Input and Output Format:\n",
    "- **Input:** A list of integers representing the dataset and an integer representing the sample size.\n",
    "- **Output:** The estimated median of the dataset and its confidence interval.\n",
    "\n",
    "### Sample Inputs and Outputs:\n",
    "- **Input:** Dataset: [35, 21, 47, 19, 13, 53, 29], Sample size: 3\n",
    "- **Output:** Estimated median: 29, Confidence interval: (21, 37)\n",
    "\n",
    "### Constraints:\n",
    "- The dataset contains a large number of integers.\n",
    "- The sample is chosen uniformly at random without replacement.\n",
    "\n",
    "**Solution:**  \n",
    "When selecting an approximate median from a large dataset using random sampling, the goal is to estimate the median value that would split the dataset into two halves. This method is particularly useful when sorting or partitioning large datasets, as in quicksort, where a good pivot can significantly affect the algorithm's efficiency.\n",
    "\n",
    "**Process Overview:**\n",
    "1. Randomly sample a subset of the dataset.\n",
    "2. Calculate the median of this sample.\n",
    "3. Use this sample median as an estimate for the overall median.\n",
    "4. Determine the confidence interval around the sample median to understand the estimate's accuracy.\n",
    "\n",
    "**Statistical Basis:**\n",
    "- The median of a sample can be used as a point estimate of the population median.\n",
    "- The standard error of the median can be approximated by dividing the sample's standard deviation by the square root of the sample size.\n",
    "- A confidence interval can then be constructed around the sample median to give a range within which the true median is likely to lie, given a confidence level.\n",
    "\n",
    "**Computing Confidence Interval:**\n",
    "- The standard deviation is a measure of the dispersion of the sample. The larger it is, the wider the confidence interval will be, indicating less certainty in the estimate.\n",
    "- The confidence level (usually 95%) tells us how confident we can be that the interval contains the true median.\n",
    "- The confidence interval is calculated using the t-distribution, which is more appropriate than the normal distribution when dealing with small sample sizes.\n",
    "\n",
    "**Python Implementation:**\n",
    "The provided Python code performs these steps using numpy for sampling and calculations and scipy.stats for confidence interval calculation. It uses the t-distribution to calculate the interval, which adjusts for smaller sample sizes. The `ddof=1` argument in the standard deviation calculation ensures that we use the sample standard deviation, which is a slightly biased estimator with a higher degree of freedom.\n",
    "\n",
    "This method of median estimation is not guaranteed to be perfectly accurate, especially with very small samples or non-uniform distributions, but it can provide a reasonable approximation quickly and with low computational overhead, which is particularly useful in algorithms like quicksort where such an estimate is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median estimate: 21.0, Confidence interval: (-6.662186848731519, 48.66218684873152)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def estimate_median_confidence_interval(data, sample_size, confidence=0.95):\n",
    "    sample = np.random.choice(data, size=sample_size, replace=False)\n",
    "    sample_median = np.median(sample)\n",
    "    std_err = np.std(sample, ddof=1) / np.sqrt(sample_size)\n",
    "    confidence_interval = stats.t.interval(confidence, df=sample_size-1, loc=sample_median, scale=std_err)\n",
    "    return sample_median, confidence_interval\n",
    "\n",
    "# Example usage\n",
    "data = [35, 21, 47, 19, 13, 53, 29]\n",
    "sample_size = 3\n",
    "median_estimate, interval = estimate_median_confidence_interval(data, sample_size)\n",
    "print(f\"Median estimate: {median_estimate}, Confidence interval: {interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection:** ChatGPT's input was crucial in crafting a problem that applied the concept of random sampling to estimate the median, akin to choosing a pivot in quicksort. I faced the challenge of balancing statistical theory with computational practicality, ensuring that the problem could be solved with a Python script. This task taught me the significance of sampling in probabilistic algorithms and deepened my understanding of statistical intervals in the context of algorithm design. ChatGPT confirmed the mathematical logic behind the sampling approach, helping me refine the solution. This reflected a meaningful learning process, emphasizing the genuine utility of AI tools in problem-solving and algorithm education.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q17. (5 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "In a distributed database system, you have a set of `r` read requests that need to be distributed evenly across `s` database shards to optimize load balancing. Your algorithm randomly assigns each read request to a shard. Analyze the distribution of read requests across the shards.\n",
    "\n",
    "### Input and Output Format:\n",
    "- **Input:** Two integers `r` (number of read requests) and `s` (number of shards).\n",
    "- **Output:** \n",
    "  - (A) The expected number of read requests per shard.\n",
    "  - (B) The likelihood that any shard has more than a certain percentage above the average load.\n",
    "  - (C) The probability that a shard receives at least `k` times the average number of read requests.\n",
    "  - (D) The chance that a shard gets less than `1/k` times the average load.\n",
    "\n",
    "### Sample Inputs and Outputs:\n",
    "- **Input:** `r = 1000` read requests, `s = 10` shards\n",
    "- **Output:**\n",
    "  - (A) Expected requests per shard: 100\n",
    "  - (B) Probability shard load > 120% average: X%\n",
    "  - (C) Probability shard load â‰¥ 2Ã— average: Y%\n",
    "  - (D) Probability shard load < 50% average: Z%\n",
    "\n",
    "### Constraints:\n",
    "- Each read request is independently assigned to a shard.\n",
    "- `r` and `s` are positive integers, with `r` typically larger than `s`.\n",
    "\n",
    "**Solution:**  \n",
    "In the context of a distributed database system, the task is to analyze how `r` read requests are distributed across `s` database shards when each request is randomly assigned to a shard. This is a typical load balancing problem where the goal is to ensure that no shard is overloaded or underutilized.\n",
    "\n",
    "**Detailed Explanation:**\n",
    "\n",
    "#### Part A: Expected Number of Read Requests Per Shard\n",
    "- **Expected Requests Per Shard:**\n",
    "  - Since each of the `r` read requests is equally likely to go to any of the `s` shards, the expected number of requests per shard is the total number of requests divided by the number of shards, i.e., `r / s`.\n",
    "\n",
    "#### Part B: Likelihood of Shard Load Above 120% of Average\n",
    "- **Calculating High Load Probability:**\n",
    "  - The binomial distribution is used because each read request can be considered a Bernoulli trial with two outcomes: it either goes to a specific shard (success) or it doesn't (failure).\n",
    "  - The probability of a shard having more than 120% of the average load is computed by finding the cumulative probability of the shard having up to 120% load and subtracting from 1.\n",
    "\n",
    "#### Part C: Probability of Shard Receiving at Least `k` Times the Average Load\n",
    "- **Determining Load `k` Times Above Average:**\n",
    "  - Using the same binomial distribution, the probability is calculated for a shard receiving at least `k` times the average number of read requests. This is found by summing the probabilities of getting `k` times the average load to the total number of requests.\n",
    "\n",
    "#### Part D: Chance of Shard Getting Less Than `1/k` Times Average Load\n",
    "- **Estimating Low Load Probability:**\n",
    "  - Conversely, the probability of a shard receiving less than `1/k` times the average load is found by calculating the cumulative distribution up to `1/k` times the average load.\n",
    "\n",
    "**Python Implementation:**\n",
    "The Python code uses the `binom` class from the `scipy.stats` module to calculate the cumulative distribution function (CDF) for binomial probabilities. This is a powerful feature of `scipy` that allows for quick and accurate computation of probabilities over a range of values in a binomial distribution.\n",
    "\n",
    "**Assumptions and Constraints:**\n",
    "- The model assumes that read requests are independent of each other, meaning the assignment of one request does not affect the assignment of another.\n",
    "- It is also assumed that `r` is typically larger than `s`, which is common in distributed systems where the number of tasks often exceeds the number of processors or shards.\n",
    "\n",
    "This analysis is particularly useful for understanding the performance and reliability of distributed systems. It helps in designing load balancers by providing a statistical understanding of how evenly distributed the load might be and allows for planning capacity and scaling strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100.0, 0.021996144965794495, 0.0, 5.995167632379605e-09)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "\n",
    "def load_distribution_analysis(r, s):\n",
    "    # A. Expected number of read requests per shard\n",
    "    expected_requests = r / s\n",
    "    \n",
    "    # B. Probability that a shard has more than 120% of the average load\n",
    "    threshold_high = int(np.ceil(expected_requests * 1.2))\n",
    "    prob_high_load = 1 - binom.cdf(threshold_high - 1, r, 1/s)\n",
    "    \n",
    "    # C. Probability that a shard receives at least k times the average load\n",
    "    k = 2\n",
    "    threshold_k_times = int(np.ceil(expected_requests * k))\n",
    "    prob_k_times_load = 1 - binom.cdf(threshold_k_times - 1, r, 1/s)\n",
    "    \n",
    "    # D. Probability that a shard gets less than 1/k times the average load\n",
    "    threshold_low = int(np.floor(expected_requests / k))\n",
    "    prob_low_load = binom.cdf(threshold_low, r, 1/s)\n",
    "\n",
    "    return expected_requests, prob_high_load, prob_k_times_load, prob_low_load\n",
    "\n",
    "# Example usage\n",
    "r = 1000  # total read requests\n",
    "s = 10    # total shards\n",
    "results = load_distribution_analysis(r, s)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection:** In crafting this new problem based on load balancing in a server cluster, I leveraged the concept of random assignment from ChatGPT to a distributed database context. The challenge was to adapt the problem to a different domain while maintaining the probabilistic nature of the load distribution. The task taught me the broad applicability of these principles across different computational systems. Writing the Python code required careful consideration of statistical methods, particularly the binomial distribution, to model the random distribution of tasks. ChatGPT's suggestions were invaluable in ensuring that the solution was not only algorithmically sound but also grounded in practical scenarios. This experience reinforced the importance of understanding the underlying principles when designing algorithmic problems, highlighting how tools like ChatGPT can complement and enhance the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18. (5 marks)  \n",
    "\n",
    "**Problem Statement**\n",
    "Given a graph with weighted edges, apply a simulated annealing algorithm to find a configuration that minimizes the total edge weight for a given set of nodes. The goal is to determine the set of nodes that, when connected, result in the lowest possible sum of weights, representing a stable and efficient network configuration.\n",
    "\n",
    "### Input and Output Format:\n",
    "- **Input:** A list of tuples representing the weighted edges of the graph, where each tuple is formatted as (node1, node2, weight).\n",
    "- **Output:** A set of nodes representing the stable configuration and the total minimized weight of the graph.\n",
    "\n",
    "### Sample Inputs and Outputs:\n",
    "- **Input:** Graph edges with weights: [(1, 2, -5), (2, 3, 6), (3, 1, 9), (1, 4, 5), (2, 4, -3), (3, 4, 1)]\n",
    "- **Output:** Stable configuration: {1, 2, 4}, Total weight: -7\n",
    "\n",
    "### Constraints:\n",
    "- The graph is undirected and may have negative weight edges.\n",
    "- The algorithm should aim to find a subset of nodes such that the sum of the connecting edge weights is minimized.\n",
    "\n",
    "**Solution:**  \n",
    "The solution to Q3 involves a problem that mimics the Hopfield Neural Network's state-flipping algorithm but is adapted to the context of finding a stable and efficient configuration in a network using simulated annealing. Here's an explanation of the solution approach and the Python code provided:\n",
    "\n",
    "**Simulated Annealing Approach:**\n",
    "1. **Initialization:** \n",
    "   - Begin with a randomly selected subset of edges from the graph as the current solution and calculate its total weight.\n",
    "   - Set an initial \"temperature\" that will gradually decrease, representing the \"cooling\" of the system.\n",
    "\n",
    "2. **Iteration and State Transition:**\n",
    "   - At each step, slightly modify the current solution by swapping edgesâ€”remove a random edge from the current solution and add another edge not currently in the solution.\n",
    "   - Calculate the new total weight after this swap to see if the solution improves.\n",
    "\n",
    "3. **Acceptance Criteria:**\n",
    "   - If the new solution has a lower total weight (better solution), accept it as the new current solution.\n",
    "   - If the new solution is worse, it can still be accepted with a probability that decreases with the temperature and depends on how much worse the new solution is compared to the current one. This probability is given by the Boltzmann distribution: \\( e^{\\frac{-\\Delta E}{T}} \\), where \\( \\Delta E \\) is the change in total weight and \\( T \\) is the current temperature.\n",
    "   - This criterion allows the algorithm to escape local minima in the search for a global minimum.\n",
    "\n",
    "4. **Cooling Schedule:**\n",
    "   - The temperature is reduced by a factor (cooling rate) at each step. This gradually reduces the probability of accepting worse solutions and allows the algorithm to \"settle\" into a minimum.\n",
    "\n",
    "5. **Termination:**\n",
    "   - The algorithm continues iterating and \"cooling\" until the temperature reaches a lower threshold, at which point it is assumed to be sufficiently close to a minimum.\n",
    "\n",
    "6. **Result:**\n",
    "   - The final stable configuration is derived from the set of nodes connected by the edges in the final solution. The total minimized weight is also reported.\n",
    "\n",
    "**Python Code Description:**\n",
    "The provided code simulates the described simulated annealing process. It starts with a random subset of edges, iteratively swaps edges in and out, and uses a cooling schedule to determine if the new set of edges should be accepted. The final output includes the set of nodes that form the stable configuration and the corresponding total weight of the selected edges.\n",
    "\n",
    "The solution applies the principles of simulated annealing, which is inspired by the physical process of cooling metal, to an optimization problem in graph theory. It demonstrates how a global minimum can be approached using probabilistic transitions, even when the search space is complex and has many local minima. This approach is particularly useful for NP-hard problems where finding the exact global minimum is computationally infeasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1, 2, 3, 4}, -7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def simulated_annealing(graph, temperature=100, cooling_rate=0.95):\n",
    "    current_solution = random.sample(graph, len(graph) // 2)\n",
    "    current_weight = sum(weight for _, _, weight in current_solution)\n",
    "    \n",
    "    while temperature > 1:\n",
    "        next_solution = current_solution.copy()\n",
    "        # Simulate edge swapping to find new solution\n",
    "        edge_to_remove = random.choice(next_solution)\n",
    "        next_solution.remove(edge_to_remove)\n",
    "        edge_to_add = random.choice([edge for edge in graph if edge not in next_solution])\n",
    "        next_solution.append(edge_to_add)\n",
    "        \n",
    "        next_weight = sum(weight for _, _, weight in next_solution)\n",
    "        \n",
    "        # Decide if we should move to the new solution\n",
    "        if next_weight < current_weight or random.uniform(0, 1) < np.exp((current_weight - next_weight) / temperature):\n",
    "            current_solution = next_solution\n",
    "            current_weight = next_weight\n",
    "        \n",
    "        temperature *= cooling_rate\n",
    "    \n",
    "    # Extract the nodes from the final solution\n",
    "    stable_configuration = {node for edge in current_solution for node in edge[:2]}\n",
    "    \n",
    "    return stable_configuration, current_weight\n",
    "\n",
    "# Example usage\n",
    "graph = [(1, 2, -5), (2, 3, 6), (3, 1, 9), (1, 4, 5), (2, 4, -3), (3, 4, 1)]\n",
    "stable_config, total_weight = simulated_annealing(graph)\n",
    "stable_config, total_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection:** In creating a problem based on the Hopfield Neural Network's state-flipping algorithm, I was inspired by the algorithm's goal to reach a stable state and applied this concept to a simulated annealing approach for network optimization. While the Hopfield network typically operates in binary state space, I adapted this to the more general problem of edge weight minimization. The main challenge was ensuring that the problem was solvable with the simulated annealing technique, which is different from the original neural network context but still captures the essence of reaching an optimized state. This process taught me about the flexibility and adaptability of algorithmic concepts across different domains. ChatGPT assisted by verifying the logic and providing algorithmic insights, emphasizing the significance of understanding the principles underlying various optimization techniques. This reinforced the value of a deep understanding of algorithms and their practical applications, as well as the potential of AI tools to facilitate exploration and learning within complex problem spaces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
